{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from ignite.engine import create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, ConfusionMatrix, mIoU\n",
    "\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_semantic_segmentation.models import ENet\n",
    "from torch_semantic_segmentation.data import CityScapesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = Compose([Normalize(), Resize(512, 1024), ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CityScapesDataset(root_dir='/home/bml/datasets/cities-scapes/', split='train', transforms=tfms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=8, num_workers=4)\n",
    "val_ds = CityScapesDataset(root_dir='/home/bml/datasets/cities-scapes/', split='val', transforms=tfms)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=8, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ENet(3, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../model_weights/different-datasets/enet-250-0.4204915103127974.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(inputs, targets, ignore_index=None):\n",
    "  inputs = torch.argmax(inputs, dim=1)\n",
    "  \n",
    "  if ignore_index is not None:\n",
    "    mask = targets != ignore_index\n",
    "    inputs = inputs[mask]\n",
    "    targets = targets[mask]\n",
    "  \n",
    "  return (inputs == targets).float().mean()\n",
    "\n",
    "def confusion_matrix(inputs, targets, num_classes):\n",
    "  inputs = torch.argmax(inputs, dim=1).flatten()\n",
    "  targets = targets.flatten()\n",
    "  \n",
    "  mask = (targets >= 0) & (targets < num_classes)\n",
    "  inputs = inputs[mask]\n",
    "  targets = targets[mask]\n",
    "  \n",
    "  indices = num_classes * targets + inputs\n",
    "  m = torch.bincount(indices, minlength=num_classes**2).reshape(num_classes, num_classes)\n",
    "  return m.float() / m.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricAverage:\n",
    "  def __init__(self, metric_fn):\n",
    "    self.metric_fn = metric_fn\n",
    "    self.count = 0\n",
    "    self.value = None\n",
    "  \n",
    "  def update(self, *args, **kwargs):\n",
    "    self.count += 1.\n",
    "    if self.value is None:\n",
    "      self.value = self.metric_fn(*args, **kwargs)\n",
    "    else:\n",
    "      self.value += self.metric_fn(*args, **kwargs)\n",
    "\n",
    "  def compute(self):\n",
    "    return self.value / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "  model.eval()\n",
    "  cm = MetricAverage(partial(confusion_matrix, num_classes=19))\n",
    "  loss = MetricAverage(partial(F.cross_entropy, ignore_index=255))\n",
    "  for inputs, targets in tqdm(dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model(inputs)\n",
    "    \n",
    "    loss.update(outputs, targets)\n",
    "    cm.update(outputs, targets)\n",
    "  return loss.compute(), cm.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 372/372 [00:57<00:00,  6.42it/s]\n",
      "100%|██████████| 63/63 [00:10<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_train, cm_train = evaluate(train_loader)\n",
    "loss_val, cm_val = evaluate(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_accuracy(cm):\n",
    "  return cm.diag().sum()\n",
    "\n",
    "def cm_miou(cm):\n",
    "  iou = cm.diag() / (cm.sum(dim=1) + cm.sum(dim=0) - cm.diag() + 1e-15)\n",
    "  return iou.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3992, device='cuda:0'), tensor(0.4387, device='cuda:0'))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_train, loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8786742687225342, 0.3388688266277313)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "cm_accuracy(cm_train).item(), cm_miou(cm_train).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8671292066574097, 0.3206044137477875)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Val\n",
    "cm_accuracy(cm_val).item(), cm_miou(cm_val).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
